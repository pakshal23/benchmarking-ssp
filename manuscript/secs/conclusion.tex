We have introduced a controlled environment for the objective study of
algorithms for linear inverse problems. We exemplified its potential on one of
the simplest categories of one-dimensional sparse stochastic processes
(L\'{e}vy processes), for which we derived the necessary tools--efficient
sampling schemes for the posterior distribution to obtain the MMSE estimator.
Despite this simplicity, our empirical results light on the fundamental
challenges of training the DnCNN model to remove artifacts in a simple Fourier
sampling reconstruction. Signals with heavy-tailed innovations will be very
poorly recovered and even the closed-form Tikhonov ($\ell_2$-regularized)
solution may perform better.

